{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igs56TKc9DBl",
        "outputId": "229a40b5-aa6f-4f10-b9ab-10e158d53efb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "âœˆï¸ PRÃ‰TRAITEMENT - SATISFACTION PASSAGERS AÃ‰RIENS\n",
            "================================================================================\n",
            "âœ… DonnÃ©es chargÃ©es avec succÃ¨s!\n",
            "ğŸ“Š Train: 103,904 lignes Ã— 24 colonnes\n",
            "ğŸ“Š Test: 25,976 lignes Ã— 24 colonnes\n",
            "\n",
            "================================================================================\n",
            "ğŸ¯ SECTION 2: SUPPRESSION DES COLONNES INUTILES\n",
            "================================================================================\n",
            "âœ… Colonnes supprimÃ©es: ['id']\n",
            "ğŸ“Š Dimensions aprÃ¨s suppression:\n",
            "   Train: 103,904 lignes Ã— 23 colonnes\n",
            "   Test: 25,976 lignes Ã— 23 colonnes\n",
            "\n",
            "================================================================================\n",
            "ğŸ”§ SECTION 3: GESTION DES VALEURS MANQUANTES\n",
            "================================================================================\n",
            "âš ï¸ Colonnes avec valeurs manquantes:\n",
            "\n",
            "ğŸ”¸ Train:\n",
            "   - Arrival Delay in Minutes: 310 valeurs (0.30%)\n",
            "\n",
            "ğŸ”¸ Test:\n",
            "   - Arrival Delay in Minutes: 83 valeurs (0.32%)\n",
            "\n",
            "ğŸ¯ StratÃ©gie d'imputation:\n",
            "   ğŸ”¸ NumÃ©riques: Imputation par mÃ©diane\n",
            "\n",
            "âœ… AprÃ¨s imputation:\n",
            "   Train - Valeurs manquantes: 0\n",
            "   Test - Valeurs manquantes: 0\n",
            "\n",
            "================================================================================\n",
            "ğŸ·ï¸ SECTION 4: ENCODAGE DES VARIABLES CATÃ‰GORIELLES\n",
            "================================================================================\n",
            "ğŸ” Variables catÃ©gorielles Ã  encoder: ['Gender', 'Customer Type', 'Type of Travel', 'Class']\n",
            "\n",
            "ğŸ”¸ Encodage de 'Gender':\n",
            "   âš¡ Encodage binaire (Label Encoding)\n",
            "   ğŸ“Š Mapping: {'Female': 0, 'Male': 1}\n",
            "\n",
            "ğŸ”¸ Encodage de 'Customer Type':\n",
            "   âš¡ Encodage binaire (Label Encoding)\n",
            "   ğŸ“Š Mapping: {'Loyal Customer': 0, 'disloyal Customer': 1}\n",
            "\n",
            "ğŸ”¸ Encodage de 'Type of Travel':\n",
            "   âš¡ Encodage binaire (Label Encoding)\n",
            "   ğŸ“Š Mapping: {'Business travel': 0, 'Personal Travel': 1}\n",
            "\n",
            "ğŸ”¸ Encodage de 'Class':\n",
            "   ğŸ¯ One-Hot Encoding (3 catÃ©gories)\n",
            "   ğŸ“Š Colonnes crÃ©Ã©es: ['Class_Eco', 'Class_Eco Plus']\n",
            "\n",
            "âœ… Encodage terminÃ©!\n",
            "ğŸ“Š Nouvelles dimensions:\n",
            "   Train: 103,904 lignes Ã— 24 colonnes\n",
            "   Test: 25,976 lignes Ã— 24 colonnes\n",
            "\n",
            "================================================================================\n",
            "ğŸ¯ SECTION 5: ENCODAGE DE LA VARIABLE CIBLE\n",
            "================================================================================\n",
            "ğŸ”¸ Encodage de la variable cible 'satisfaction'\n",
            "ğŸ“Š Mapping cible: {'neutral or dissatisfied': 0, 'satisfied': 1}\n",
            "   - 0: neutral or dissatisfied (classe majoritaire)\n",
            "   - 1: satisfied (classe minoritaire)\n",
            "\n",
            "================================================================================\n",
            "ğŸ“ˆ SECTION 6: GESTION DES OUTLIERS\n",
            "================================================================================\n",
            "ğŸ” Gestion des outliers via winsorization ou transformation:\n",
            "ğŸ”¸ Age: 1318 outliers â†’ Winsorization (1%-99%)\n",
            "ğŸ”¸ Flight Distance: 1868 outliers â†’ Winsorization (1%-99%)\n",
            "ğŸ”¸ Gate location: 1 outliers â†’ Winsorization (1%-99%)\n",
            "ğŸ”¸ Food and drink: 107 outliers â†’ Winsorization (1%-99%)\n",
            "ğŸ”¸ Seat comfort: 1 outliers â†’ Winsorization (1%-99%)\n",
            "ğŸ”¸ Inflight entertainment: 14 outliers â†’ Winsorization (1%-99%)\n",
            "ğŸ”¸ On-board service: 3 outliers â†’ Winsorization (1%-99%)\n",
            "ğŸ”¸ Leg room service: 472 outliers â†’ Winsorization (1%-99%)\n",
            "ğŸ”¸ Checkin service: 1 outliers â†’ Winsorization (1%-99%)\n",
            "ğŸ”¸ Inflight service: 3 outliers â†’ Winsorization (1%-99%)\n",
            "ğŸ”¸ Cleanliness: 12 outliers â†’ Winsorization (1%-99%)\n",
            "ğŸ”¸ Departure Delay in Minutes: Forte asymÃ©trie dÃ©tectÃ©e â†’ Transformation log\n",
            "ğŸ”¸ Arrival Delay in Minutes: Forte asymÃ©trie dÃ©tectÃ©e â†’ Transformation log\n",
            "\n",
            "âœ… Gestion des outliers terminÃ©e!\n",
            "\n",
            "================================================================================\n",
            "âš–ï¸ SECTION 7: NORMALISATION/STANDARDISATION\n",
            "================================================================================\n",
            "ğŸ” 23 features Ã  normaliser\n",
            "âœ… Normalisation avec RobustScaler terminÃ©e!\n",
            "\n",
            "================================================================================\n",
            "ğŸ” SECTION 8: SÃ‰LECTION DE FEATURES\n",
            "================================================================================\n",
            "1ï¸âƒ£  Suppression des features Ã  variance nulle:\n",
            "   âœ… 23 features conservÃ©es sur 23\n",
            "\n",
            "2ï¸âƒ£  SÃ©lection basÃ©e sur ANOVA F-value:\n",
            "   âœ… Top 20 features sÃ©lectionnÃ©es:\n",
            "       1. Online boarding                : 35296.58\n",
            "       2. Class_Eco                      : 26547.47\n",
            "       3. Type of Travel                 : 26236.00\n",
            "       4. Inflight entertainment         : 19562.98\n",
            "       5. Seat comfort                   : 14453.71\n",
            "       6. On-board service               : 12050.77\n",
            "       7. Leg room service               : 11439.64\n",
            "       8. Cleanliness                    : 10670.56\n",
            "       9. Flight Distance                : 10213.46\n",
            "      10. Inflight wifi service          : 9132.66\n",
            "\n",
            "ğŸ“Š Dimensions finales:\n",
            "   X_train: (103904, 20)\n",
            "   X_test: (25976, 20)\n",
            "\n",
            "================================================================================\n",
            "ğŸ’¾ SECTION 9: SAUVEGARDE DES DONNÃ‰ES PRÃ‰TRAITÃ‰ES\n",
            "================================================================================\n",
            "âœ… DonnÃ©es sauvegardÃ©es avec succÃ¨s!\n",
            "ğŸ“ Dossier: processed/\n",
            "ğŸ“„ Fichiers gÃ©nÃ©rÃ©s:\n",
            "   - X_train_processed.csv\n",
            "   - X_test_processed.csv\n",
            "   - y_train_processed.csv\n",
            "   - y_test_processed.csv (si disponible)\n",
            "   - preprocessing_objects.pkl\n",
            "\n",
            "================================================================================\n",
            "ğŸ“Š SECTION 10: RÃ‰SUMÃ‰ DU PRÃ‰TRAITEMENT\n",
            "================================================================================\n",
            "ğŸ¯ Ã‰TAPES EFFECTUÃ‰ES:\n",
            "\n",
            "1. âœ… Chargement des donnÃ©es (train.csv, test.csv)\n",
            "2. âœ… Suppression des colonnes inutiles (id)\n",
            "3. âœ… Gestion des valeurs manquantes (imputation mÃ©diane/mode)\n",
            "4. âœ… Encodage des variables catÃ©gorielles:\n",
            "   - Label Encoding pour variables binaires\n",
            "   - One-Hot Encoding pour variables multi-classes\n",
            "5. âœ… Encodage de la variable cible (satisfaction â†’ 0/1)\n",
            "6. âœ… Gestion des outliers:\n",
            "   - Transformation log pour variables trÃ¨s asymÃ©triques\n",
            "   - Winsorization pour outliers modÃ©rÃ©s\n",
            "7. âœ… Normalisation avec RobustScaler\n",
            "8. âœ… SÃ©lection de features:\n",
            "   - VarianceThreshold (suppression features Ã  variance quasi-nulle)\n",
            "   - SelectKBest (sÃ©lection des 20 meilleures features)\n",
            "9. âœ… Sauvegarde des donnÃ©es prÃ©traitÃ©es\n",
            "\n",
            "ğŸ“ˆ STATISTIQUES FINALES:\n",
            "   - Nombre de features initial: 23\n",
            "   - Nombre de features final: 20\n",
            "   - RÃ©duction: 13.0%\n",
            "   - Taille Ã©chantillon train: 103,904\n",
            "   - Taille Ã©chantillon test: 25,976\n",
            "\n",
            "ğŸ” APERÃ‡U DES DONNÃ‰ES PRÃ‰TRAITÃ‰ES (X_train):\n",
            "   Customer Type       Age  Type of Travel  Flight Distance  \\\n",
            "0            0.0 -1.125000             1.0        -0.288187   \n",
            "1            1.0 -0.625000             0.0        -0.457487   \n",
            "2            0.0 -0.583333             0.0         0.224981   \n",
            "3            0.0 -0.625000             0.0        -0.211437   \n",
            "4            0.0  0.875000             0.0        -0.473288   \n",
            "\n",
            "   Inflight wifi service  Ease of Online booking  Food and drink  \\\n",
            "0                    0.0                     0.0             1.0   \n",
            "1                    0.0                     0.0            -1.0   \n",
            "2                   -0.5                    -0.5             1.0   \n",
            "3                   -0.5                     1.0            -0.5   \n",
            "4                    0.0                     0.0             0.5   \n",
            "\n",
            "   Online boarding  Seat comfort  Inflight entertainment  On-board service  \\\n",
            "0              0.0      0.333333                     0.5               0.0   \n",
            "1              0.0     -1.000000                    -1.5              -1.5   \n",
            "2              1.0      0.333333                     0.5               0.0   \n",
            "3             -0.5     -0.666667                    -1.0              -1.0   \n",
            "4              1.0      0.333333                    -0.5              -0.5   \n",
            "\n",
            "   Leg room service  Baggage handling  Checkin service  Inflight service  \\\n",
            "0              -0.5               0.0              1.0               0.5   \n",
            "1               0.5              -0.5             -2.0               0.0   \n",
            "2              -0.5               0.0              1.0               0.0   \n",
            "3               0.5              -0.5             -2.0               0.0   \n",
            "4               0.0               0.0              0.0              -0.5   \n",
            "\n",
            "   Cleanliness  Class_Eco  Class_Eco Plus  Departure Delay in Minutes_log  \\\n",
            "0          1.0        0.0             1.0                        1.270238   \n",
            "1         -1.0        0.0             0.0                        0.270238   \n",
            "2          1.0        0.0             0.0                        0.000000   \n",
            "3         -0.5        0.0             0.0                        0.968794   \n",
            "4          0.0        0.0             0.0                        0.000000   \n",
            "\n",
            "   Arrival Delay in Minutes_log  \n",
            "0                      1.115716  \n",
            "1                      0.737350  \n",
            "2                      0.000000  \n",
            "3                      0.872503  \n",
            "4                      0.000000  \n",
            "\n",
            "ğŸ” APERÃ‡U DE LA CIBLE (y_train):\n",
            "0    0\n",
            "1    0\n",
            "2    1\n",
            "3    0\n",
            "4    1\n",
            "Name: satisfaction, dtype: int32\n",
            "\n",
            "================================================================================\n",
            "âœ… PRÃ‰TRAITEMENT TERMINÃ‰ - PRÃŠT POUR LA MODÃ‰LISATION!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Airline_Passenger_Satisfaction_Preprocessing.ipynb\n",
        "\n",
        "PrÃ©traitement des donnÃ©es - Satisfaction Passagers AÃ©riens\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ“ SECTION 1: CHARGEMENT DES DONNÃ‰ES\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"âœˆï¸ PRÃ‰TRAITEMENT - SATISFACTION PASSAGERS AÃ‰RIENS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Charger les donnÃ©es\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "print(f\"âœ… DonnÃ©es chargÃ©es avec succÃ¨s!\")\n",
        "print(f\"ğŸ“Š Train: {train_df.shape[0]:,} lignes Ã— {train_df.shape[1]} colonnes\")\n",
        "print(f\"ğŸ“Š Test: {test_df.shape[0]:,} lignes Ã— {test_df.shape[1]} colonnes\")\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ¯ SECTION 2: SUPPRESSION DES COLONNES INUTILES\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ¯ SECTION 2: SUPPRESSION DES COLONNES INUTILES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Colonnes Ã  supprimer basÃ©es sur l'EDA\n",
        "cols_to_drop = ['id']  # ID unique, pas informatif\n",
        "\n",
        "# Supprimer les colonnes\n",
        "train_df = train_df.drop(columns=cols_to_drop, errors='ignore')\n",
        "test_df = test_df.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "print(f\"âœ… Colonnes supprimÃ©es: {cols_to_drop}\")\n",
        "print(f\"ğŸ“Š Dimensions aprÃ¨s suppression:\")\n",
        "print(f\"   Train: {train_df.shape[0]:,} lignes Ã— {train_df.shape[1]} colonnes\")\n",
        "print(f\"   Test: {test_df.shape[0]:,} lignes Ã— {test_df.shape[1]} colonnes\")\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ”§ SECTION 3: GESTION DES VALEURS MANQUANTES\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ”§ SECTION 3: GESTION DES VALEURS MANQUANTES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Identifier les colonnes avec valeurs manquantes\n",
        "missing_train = train_df.isnull().sum()\n",
        "missing_test = test_df.isnull().sum()\n",
        "\n",
        "missing_cols_train = missing_train[missing_train > 0].index.tolist()\n",
        "missing_cols_test = missing_test[missing_test > 0].index.tolist()\n",
        "\n",
        "if missing_cols_train or missing_cols_test:\n",
        "    print(\"âš ï¸ Colonnes avec valeurs manquantes:\")\n",
        "\n",
        "    for df_name, df_missing, missing_cols in [(\"Train\", missing_train, missing_cols_train),\n",
        "                                              (\"Test\", missing_test, missing_cols_test)]:\n",
        "        if missing_cols:\n",
        "            print(f\"\\nğŸ”¸ {df_name}:\")\n",
        "            for col in missing_cols:\n",
        "                missing_pct = (df_missing[col] / len(train_df if df_name == \"Train\" else test_df)) * 100\n",
        "                print(f\"   - {col}: {df_missing[col]} valeurs ({missing_pct:.2f}%)\")\n",
        "\n",
        "    # StratÃ©gie d'imputation basÃ©e sur l'EDA\n",
        "    print(\"\\nğŸ¯ StratÃ©gie d'imputation:\")\n",
        "\n",
        "    # 1. Colonnes catÃ©gorielles: Mode\n",
        "    categorical_cols = train_df.select_dtypes(include=['object']).columns.tolist()\n",
        "    cat_missing = [col for col in categorical_cols if col in missing_cols_train or col in missing_cols_test]\n",
        "\n",
        "    if cat_missing:\n",
        "        print(\"   ğŸ”¸ CatÃ©gorielles: Imputation par mode\")\n",
        "        for col in cat_missing:\n",
        "            if col in train_df.columns:\n",
        "                mode_val = train_df[col].mode()[0]\n",
        "                train_df[col] = train_df[col].fillna(mode_val)\n",
        "            if col in test_df.columns:\n",
        "                mode_val = test_df[col].mode()[0] if not test_df[col].mode().empty else train_df[col].mode()[0]\n",
        "                test_df[col] = test_df[col].fillna(mode_val)\n",
        "\n",
        "    # 2. Colonnes numÃ©riques: MÃ©diane (robuste aux outliers)\n",
        "    numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    num_missing = [col for col in numeric_cols if col in missing_cols_train or col in missing_cols_test]\n",
        "\n",
        "    if num_missing:\n",
        "        print(\"   ğŸ”¸ NumÃ©riques: Imputation par mÃ©diane\")\n",
        "        for col in num_missing:\n",
        "            if col in train_df.columns:\n",
        "                median_val = train_df[col].median()\n",
        "                train_df[col] = train_df[col].fillna(median_val)\n",
        "            if col in test_df.columns:\n",
        "                median_val = test_df[col].median() if not test_df[col].isnull().all() else train_df[col].median()\n",
        "                test_df[col] = test_df[col].fillna(median_val)\n",
        "\n",
        "    # VÃ©rifier aprÃ¨s imputation\n",
        "    print(\"\\nâœ… AprÃ¨s imputation:\")\n",
        "    print(f\"   Train - Valeurs manquantes: {train_df.isnull().sum().sum()}\")\n",
        "    print(f\"   Test - Valeurs manquantes: {test_df.isnull().sum().sum()}\")\n",
        "else:\n",
        "    print(\"âœ… Aucune valeur manquante dÃ©tectÃ©e!\")\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ·ï¸ SECTION 4: ENCODAGE DES VARIABLES CATÃ‰GORIELLES\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ·ï¸ SECTION 4: ENCODAGE DES VARIABLES CATÃ‰GORIELLES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Identifier les colonnes catÃ©gorielles\n",
        "categorical_cols = train_df.select_dtypes(include=['object']).columns.tolist()\n",
        "target_col = 'satisfaction'\n",
        "\n",
        "# Retirer la cible des variables catÃ©gorielles\n",
        "if target_col in categorical_cols:\n",
        "    categorical_cols.remove(target_col)\n",
        "\n",
        "print(f\"ğŸ” Variables catÃ©gorielles Ã  encoder: {categorical_cols}\")\n",
        "\n",
        "# Dictionnaire pour stocker les encodeurs\n",
        "encoders = {}\n",
        "\n",
        "# Encodage spÃ©cifique basÃ© sur l'analyse de l'EDA\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\nğŸ”¸ Encodage de '{col}':\")\n",
        "\n",
        "    # Encodage binaire pour les variables Ã  2 catÃ©gories\n",
        "    if train_df[col].nunique() == 2:\n",
        "        print(f\"   âš¡ Encodage binaire (Label Encoding)\")\n",
        "        le = LabelEncoder()\n",
        "\n",
        "        # Appliquer sur train\n",
        "        train_df[col] = le.fit_transform(train_df[col])\n",
        "\n",
        "        # Appliquer sur test en utilisant les mÃªmes classes\n",
        "        # Pour les nouvelles catÃ©gories dans test, on utilise une valeur par dÃ©faut\n",
        "        test_categories = set(test_df[col].unique())\n",
        "        train_categories = set(le.classes_)\n",
        "\n",
        "        if not test_categories.issubset(train_categories):\n",
        "            print(f\"   âš ï¸  CatÃ©gories inconnues dans test: {test_categories - train_categories}\")\n",
        "            # Remplacer les catÃ©gories inconnues par la plus frÃ©quente\n",
        "            most_frequent = train_df[col].mode()[0]\n",
        "            test_df[col] = test_df[col].apply(lambda x: x if x in le.classes_ else le.classes_[most_frequent])\n",
        "\n",
        "        test_df[col] = le.transform(test_df[col])\n",
        "        encoders[col] = le\n",
        "\n",
        "        print(f\"   ğŸ“Š Mapping: {dict(zip(le.classes_, range(len(le.classes_))))}\")\n",
        "\n",
        "    # One-Hot Encoding pour les variables Ã  >2 catÃ©gories\n",
        "    else:\n",
        "        print(f\"   ğŸ¯ One-Hot Encoding ({train_df[col].nunique()} catÃ©gories)\")\n",
        "\n",
        "        # CrÃ©er les variables dummy\n",
        "        dummies_train = pd.get_dummies(train_df[col], prefix=col, drop_first=True)\n",
        "        dummies_test = pd.get_dummies(test_df[col], prefix=col, drop_first=True)\n",
        "\n",
        "        # S'assurer que test a les mÃªmes colonnes que train\n",
        "        missing_cols = set(dummies_train.columns) - set(dummies_test.columns)\n",
        "        for c in missing_cols:\n",
        "            dummies_test[c] = 0\n",
        "\n",
        "        # Garder seulement les colonnes dans le mÃªme ordre\n",
        "        dummies_test = dummies_test[dummies_train.columns]\n",
        "\n",
        "        # Supprimer la colonne originale et ajouter les dummies\n",
        "        train_df = pd.concat([train_df.drop(columns=[col]), dummies_train], axis=1)\n",
        "        test_df = pd.concat([test_df.drop(columns=[col]), dummies_test], axis=1)\n",
        "\n",
        "        print(f\"   ğŸ“Š Colonnes crÃ©Ã©es: {list(dummies_train.columns)}\")\n",
        "\n",
        "print(f\"\\nâœ… Encodage terminÃ©!\")\n",
        "print(f\"ğŸ“Š Nouvelles dimensions:\")\n",
        "print(f\"   Train: {train_df.shape[0]:,} lignes Ã— {train_df.shape[1]} colonnes\")\n",
        "print(f\"   Test: {test_df.shape[0]:,} lignes Ã— {test_df.shape[1]} colonnes\")\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ¯ SECTION 5: ENCODAGE DE LA VARIABLE CIBLE\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ¯ SECTION 5: ENCODAGE DE LA VARIABLE CIBLE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Encoder la variable cible\n",
        "print(\"ğŸ”¸ Encodage de la variable cible 'satisfaction'\")\n",
        "target_encoder = LabelEncoder()\n",
        "train_df[target_col] = target_encoder.fit_transform(train_df[target_col])\n",
        "\n",
        "# VÃ©rifier si la variable cible existe dans test (pour l'Ã©valuation)\n",
        "if target_col in test_df.columns:\n",
        "    test_df[target_col] = target_encoder.transform(test_df[target_col])\n",
        "\n",
        "print(f\"ğŸ“Š Mapping cible: {dict(zip(target_encoder.classes_, target_encoder.transform(target_encoder.classes_)))}\")\n",
        "print(f\"   - 0: {target_encoder.classes_[0]} (classe majoritaire)\")\n",
        "print(f\"   - 1: {target_encoder.classes_[1]} (classe minoritaire)\")\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ“ˆ SECTION 6: GESTION DES OUTLIERS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ“ˆ SECTION 6: GESTION DES OUTLIERS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Identifier les variables numÃ©riques (aprÃ¨s encodage)\n",
        "numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "if target_col in numeric_cols:\n",
        "    numeric_cols.remove(target_col)\n",
        "\n",
        "# Variables avec forte asymÃ©trie dÃ©tectÃ©es dans l'EDA\n",
        "skewed_cols = ['Departure Delay in Minutes', 'Arrival Delay in Minutes']\n",
        "\n",
        "print(\"ğŸ” Gestion des outliers via winsorization ou transformation:\")\n",
        "\n",
        "for col in numeric_cols:\n",
        "    if col in skewed_cols:\n",
        "        print(f\"ğŸ”¸ {col}: Forte asymÃ©trie dÃ©tectÃ©e â†’ Transformation log\")\n",
        "\n",
        "        # Ajouter 1 pour Ã©viter log(0)\n",
        "        train_df[f'{col}_log'] = np.log1p(train_df[col])\n",
        "        test_df[f'{col}_log'] = np.log1p(test_df[col])\n",
        "\n",
        "        # Supprimer la colonne originale\n",
        "        train_df = train_df.drop(columns=[col])\n",
        "        test_df = test_df.drop(columns=[col])\n",
        "    else:\n",
        "        # Winsorization pour les autres variables avec outliers\n",
        "        Q1 = train_df[col].quantile(0.01)\n",
        "        Q3 = train_df[col].quantile(0.99)\n",
        "\n",
        "        outliers_count = ((train_df[col] < Q1) | (train_df[col] > Q3)).sum()\n",
        "        if outliers_count > 0 and outliers_count < len(train_df) * 0.05:\n",
        "            print(f\"ğŸ”¸ {col}: {outliers_count} outliers â†’ Winsorization (1%-99%)\")\n",
        "\n",
        "            # Appliquer winsorization\n",
        "            train_df[col] = train_df[col].clip(Q1, Q3)\n",
        "            test_df[col] = test_df[col].clip(Q1, Q3)\n",
        "\n",
        "print(\"\\nâœ… Gestion des outliers terminÃ©e!\")\n",
        "\n",
        "# ============================================================================\n",
        "# âš–ï¸ SECTION 7: NORMALISATION/STANDARDISATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"âš–ï¸ SECTION 7: NORMALISATION/STANDARDISATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Identifier les colonnes Ã  normaliser\n",
        "features_to_scale = [col for col in train_df.columns if col != target_col]\n",
        "\n",
        "print(f\"ğŸ” {len(features_to_scale)} features Ã  normaliser\")\n",
        "\n",
        "# SÃ©parer features et target\n",
        "X_train = train_df.drop(columns=[target_col])\n",
        "y_train = train_df[target_col]\n",
        "\n",
        "X_test = test_df.drop(columns=[target_col], errors='ignore')\n",
        "y_test = test_df[target_col] if target_col in test_df.columns else None\n",
        "\n",
        "# Appliquer RobustScaler (robuste aux outliers)\n",
        "scaler = RobustScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convertir en DataFrame pour conserver les noms de colonnes\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(\"âœ… Normalisation avec RobustScaler terminÃ©e!\")\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ” SECTION 8: SÃ‰LECTION DE FEATURES\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ” SECTION 8: SÃ‰LECTION DE FEATURES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Supprimer les features avec variance quasi-nulle\n",
        "print(\"1ï¸âƒ£  Suppression des features Ã  variance nulle:\")\n",
        "selector_variance = VarianceThreshold(threshold=0.01)\n",
        "X_train_var = selector_variance.fit_transform(X_train_scaled_df)\n",
        "X_test_var = selector_variance.transform(X_test_scaled_df)\n",
        "\n",
        "# RÃ©cupÃ©rer les noms des colonnes conservÃ©es\n",
        "selected_features = X_train_scaled_df.columns[selector_variance.get_support()]\n",
        "print(f\"   âœ… {len(selected_features)} features conservÃ©es sur {X_train_scaled_df.shape[1]}\")\n",
        "\n",
        "# 2. SÃ©lection basÃ©e sur les tests statistiques (ANOVA F-value)\n",
        "print(\"\\n2ï¸âƒ£  SÃ©lection basÃ©e sur ANOVA F-value:\")\n",
        "k = min(20, len(selected_features))  # Garder les 20 meilleures features\n",
        "selector_kbest = SelectKBest(score_func=f_classif, k=k)\n",
        "X_train_selected = selector_kbest.fit_transform(X_train_scaled_df[selected_features], y_train)\n",
        "X_test_selected = selector_kbest.transform(X_test_scaled_df[selected_features])\n",
        "\n",
        "# RÃ©cupÃ©rer les noms des colonnes sÃ©lectionnÃ©es\n",
        "selected_features_kbest = selected_features[selector_kbest.get_support()]\n",
        "\n",
        "print(f\"   âœ… Top {k} features sÃ©lectionnÃ©es:\")\n",
        "scores = selector_kbest.scores_\n",
        "indices = np.argsort(scores)[::-1]\n",
        "\n",
        "for i in range(min(10, len(scores))):\n",
        "    idx = indices[i]\n",
        "    print(f\"      {i+1:2d}. {selected_features[idx]:30} : {scores[idx]:.2f}\")\n",
        "\n",
        "# Mettre Ã  jour les DataFrames\n",
        "X_train_final = pd.DataFrame(X_train_selected, columns=selected_features_kbest, index=X_train.index)\n",
        "X_test_final = pd.DataFrame(X_test_selected, columns=selected_features_kbest, index=X_test.index)\n",
        "\n",
        "print(f\"\\nğŸ“Š Dimensions finales:\")\n",
        "print(f\"   X_train: {X_train_final.shape}\")\n",
        "print(f\"   X_test: {X_test_final.shape}\")\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ’¾ SECTION 9: SAUVEGARDE DES DONNÃ‰ES PRÃ‰TRAITÃ‰ES\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ’¾ SECTION 9: SAUVEGARDE DES DONNÃ‰ES PRÃ‰TRAITÃ‰ES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Sauvegarder les donnÃ©es prÃ©traitÃ©es\n",
        "output_path = 'processed/'\n",
        "\n",
        "# CrÃ©er le dossier si nÃ©cessaire\n",
        "import os\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# Sauvegarder les donnÃ©es\n",
        "X_train_final.to_csv(f'{output_path}X_train_processed.csv', index=False)\n",
        "X_test_final.to_csv(f'{output_path}X_test_processed.csv', index=False)\n",
        "\n",
        "y_train.to_csv(f'{output_path}y_train_processed.csv', index=False)\n",
        "if y_test is not None:\n",
        "    y_test.to_csv(f'{output_path}y_test_processed.csv', index=False)\n",
        "\n",
        "# Sauvegarder les objets de preprocessing\n",
        "import joblib\n",
        "preprocessing_objects = {\n",
        "    'scaler': scaler,\n",
        "    'variance_selector': selector_variance,\n",
        "    'kbest_selector': selector_kbest,\n",
        "    'target_encoder': target_encoder,\n",
        "    'encoders': encoders,\n",
        "    'selected_features': selected_features_kbest.tolist()\n",
        "}\n",
        "\n",
        "joblib.dump(preprocessing_objects, f'{output_path}preprocessing_objects.pkl')\n",
        "\n",
        "print(\"âœ… DonnÃ©es sauvegardÃ©es avec succÃ¨s!\")\n",
        "print(f\"ğŸ“ Dossier: {output_path}\")\n",
        "print(f\"ğŸ“„ Fichiers gÃ©nÃ©rÃ©s:\")\n",
        "print(f\"   - X_train_processed.csv\")\n",
        "print(f\"   - X_test_processed.csv\")\n",
        "print(f\"   - y_train_processed.csv\")\n",
        "print(f\"   - y_test_processed.csv (si disponible)\")\n",
        "print(f\"   - preprocessing_objects.pkl\")\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ“Š SECTION 10: RÃ‰SUMÃ‰ DU PRÃ‰TRAITEMENT\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ“Š SECTION 10: RÃ‰SUMÃ‰ DU PRÃ‰TRAITEMENT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"ğŸ¯ Ã‰TAPES EFFECTUÃ‰ES:\")\n",
        "print(\"\"\"\n",
        "1. âœ… Chargement des donnÃ©es (train.csv, test.csv)\n",
        "2. âœ… Suppression des colonnes inutiles (id)\n",
        "3. âœ… Gestion des valeurs manquantes (imputation mÃ©diane/mode)\n",
        "4. âœ… Encodage des variables catÃ©gorielles:\n",
        "   - Label Encoding pour variables binaires\n",
        "   - One-Hot Encoding pour variables multi-classes\n",
        "5. âœ… Encodage de la variable cible (satisfaction â†’ 0/1)\n",
        "6. âœ… Gestion des outliers:\n",
        "   - Transformation log pour variables trÃ¨s asymÃ©triques\n",
        "   - Winsorization pour outliers modÃ©rÃ©s\n",
        "7. âœ… Normalisation avec RobustScaler\n",
        "8. âœ… SÃ©lection de features:\n",
        "   - VarianceThreshold (suppression features Ã  variance quasi-nulle)\n",
        "   - SelectKBest (sÃ©lection des 20 meilleures features)\n",
        "9. âœ… Sauvegarde des donnÃ©es prÃ©traitÃ©es\n",
        "\"\"\")\n",
        "\n",
        "print(\"ğŸ“ˆ STATISTIQUES FINALES:\")\n",
        "print(f\"   - Nombre de features initial: {train_df.shape[1] - 1}\")\n",
        "print(f\"   - Nombre de features final: {X_train_final.shape[1]}\")\n",
        "print(f\"   - RÃ©duction: {((train_df.shape[1] - 1 - X_train_final.shape[1]) / (train_df.shape[1] - 1) * 100):.1f}%\")\n",
        "print(f\"   - Taille Ã©chantillon train: {X_train_final.shape[0]:,}\")\n",
        "print(f\"   - Taille Ã©chantillon test: {X_test_final.shape[0]:,}\")\n",
        "\n",
        "# AperÃ§u des donnÃ©es prÃ©traitÃ©es\n",
        "print(\"\\nğŸ” APERÃ‡U DES DONNÃ‰ES PRÃ‰TRAITÃ‰ES (X_train):\")\n",
        "print(X_train_final.head())\n",
        "print(f\"\\nğŸ” APERÃ‡U DE LA CIBLE (y_train):\")\n",
        "print(y_train.head())\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"âœ… PRÃ‰TRAITEMENT TERMINÃ‰ - PRÃŠT POUR LA MODÃ‰LISATION!\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
